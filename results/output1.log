torchrun --nproc_per_node 4 --nnodes 2 --node_rank 1 --master_addr 10.3.0.26 --master_port 32364 pretrain_megatron_llama.py --save /mnt/output_megatron_llama2/checkpoint/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000 --train-data-path /gfshome/llama2-datasets/wudao_llamabpe_text_document --lr 1e-5 --min-lr 1e-6 --lr-decay-style linear --adam-beta1 0.9 --adam-beta2 0.95 --weight-decay 0.1 --clip-grad 1.0 --init-method-std 0.006 --lr-decay-iters 400 --lr-warmup-iters 9 --train-iters 400 --micro-batch-size 1 --global-batch-size 8 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --ffn-hidden-size 11008 --seq-length 128 --max-position-embeddings 4096 --max-padding-length 128 --log-interval 1 --eval-interval 10000 --eval-iters 10 --save-interval 100000 --tensorboard-queue-size 1 --tensorboard-dir /mnt/output_megatron_llama2/tensorboard/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000_2024.11.22-04.22.02 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --tensor-model-parallel-size 1 --pipeline-model-parallel-size 4 --no-load-optim --no-load-rng --num-workers 0 --seed 1234 --max-padding-length 128 --extra-vocab-size 0 --patch-tokenizer-type LLamaTokenizer --dataset LLama-Pretrain-Idxmap --swiglu --normalization RMSNorm --use-llama2-rotary-position-embeddings --position-embedding-type rope --untie-embeddings-and-output-weights --disable-bias-linear --forward-backward-disaggregating --bf16 --load /gfshome/llama2-ckpts/Llama-2-7b-hf-to-megatron-tp1-pp4 --recompute-activations --use-distributed-optimizer
> setting tensorboard ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 1619066880
 > number of parameters on (tensor, pipeline) model parallel rank (0, 3): 1750142976
Rank level: Rank level:0  30Rank level:
 Rank level:2 
0  20 
3
(min, max) time across ranks (ms):
    load-checkpoint ................................: (7727.37, 7727.76)
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (9780.02, 9801.78)
    train/valid/test-data-iterators-setup ..........: (1469.89, 2499.17)
 iteration        1/     400 | consumed samples:            8 | elapsed time per iteration (ms): 2989.3 | learning rate: 1.111E-06 | global batch size:     8 | lm loss: 1.068049E+01 | loss scale: 1.0 | grad norm: 47.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
[Rank 4] (after 1 iterations) memory (MB) | allocated: 18554.880859375 | max allocated: 18554.88427734375 | reserved: 18928.0 | max reserved: 18928.0
[Rank 6] (after 1 iterations) memory (MB) | allocated: 20054.9287109375 | max allocated: 20054.93212890625 | reserved: 20642.0 | max reserved: 20642.0
 iteration        2/     400 | consumed samples:           16 | elapsed time per iteration (ms): 1567.5 | learning rate: 2.222E-06 | global batch size:     8 | lm loss: 1.061451E+01 | loss scale: 1.0 | grad norm: 204.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        3/     400 | consumed samples:           24 | elapsed time per iteration (ms): 1506.0 | learning rate: 3.333E-06 | global batch size:     8 | lm loss: 9.666226E+00 | loss scale: 1.0 | grad norm: 59.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        4/     400 | consumed samples:           32 | elapsed time per iteration (ms): 1493.3 | learning rate: 4.444E-06 | global batch size:     8 | lm loss: 1.067665E+01 | loss scale: 1.0 | grad norm: 70.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        5/     400 | consumed samples:           40 | elapsed time per iteration (ms): 1534.9 | learning rate: 5.556E-06 | global batch size:     8 | lm loss: 1.098933E+01 | loss scale: 1.0 | grad norm: 46.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        6/     400 | consumed samples:           48 | elapsed time per iteration (ms): 1465.0 | learning rate: 6.667E-06 | global batch size:     8 | lm loss: 9.861741E+00 | loss scale: 1.0 | grad norm: 41.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        7/     400 | consumed samples:           56 | elapsed time per iteration (ms): 1503.9 | learning rate: 7.778E-06 | global batch size:     8 | lm loss: 9.623478E+00 | loss scale: 1.0 | grad norm: 68.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        8/     400 | consumed samples:           64 | elapsed time per iteration (ms): 1499.3 | learning rate: 8.889E-06 | global batch size:     8 | lm loss: 8.693103E+00 | loss scale: 1.0 | grad norm: 29.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        9/     400 | consumed samples:           72 | elapsed time per iteration (ms): 1500.1 | learning rate: 1.000E-05 | global batch size:     8 | lm loss: 7.941988E+00 | loss scale: 1.0 | grad norm: 20.591 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       10/     400 | consumed samples:           80 | elapsed time per iteration (ms): 1501.1 | learning rate: 9.977E-06 | global batch size:     8 | lm loss: 7.846517E+00 | loss scale: 1.0 | grad norm: 53.243 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       11/     400 | consumed samples:           88 | elapsed time per iteration (ms): 1496.2 | learning rate: 9.954E-06 | global batch size:     8 | lm loss: 8.174131E+00 | loss scale: 1.0 | grad norm: 27.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       12/     400 | consumed samples:           96 | elapsed time per iteration (ms): 1447.7 | learning rate: 9.931E-06 | global batch size:     8 | lm loss: 7.454420E+00 | loss scale: 1.0 | grad norm: 16.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       13/     400 | consumed samples:          104 | elapsed time per iteration (ms): 1496.8 | learning rate: 9.908E-06 | global batch size:     8 | lm loss: 6.947242E+00 | loss scale: 1.0 | grad norm: 9.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       14/     400 | consumed samples:          112 | elapsed time per iteration (ms): 1455.5 | learning rate: 9.885E-06 | global batch size:     8 | lm loss: 6.520373E+00 | loss scale: 1.0 | grad norm: 9.342 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       15/     400 | consumed samples:          120 | elapsed time per iteration (ms): 2601.6 | learning rate: 9.862E-06 | global batch size:     8 | lm loss: 6.671080E+00 | loss scale: 1.0 | grad norm: 10.152 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       16/     400 | consumed samples:          128 | elapsed time per iteration (ms): 2425.0 | learning rate: 9.839E-06 | global batch size:     8 | lm loss: 6.328038E+00 | loss scale: 1.0 | grad norm: 30.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       17/     400 | consumed samples:          136 | elapsed time per iteration (ms): 2474.4 | learning rate: 9.816E-06 | global batch size:     8 | lm loss: 6.582240E+00 | loss scale: 1.0 | grad norm: 13.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       18/     400 | consumed samples:          144 | elapsed time per iteration (ms): 2398.0 | learning rate: 9.793E-06 | global batch size:     8 | lm loss: 6.029513E+00 | loss scale: 1.0 | grad norm: 7.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       19/     400 | consumed samples:          152 | elapsed time per iteration (ms): 2549.3 | learning rate: 9.770E-06 | global batch size:     8 | lm loss: 6.138690E+00 | loss scale: 1.0 | grad norm: 7.366 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       20/     400 | consumed samples:          160 | elapsed time per iteration (ms): 1497.7 | learning rate: 9.747E-06 | global batch size:     8 | lm loss: 6.273012E+00 | loss scale: 1.0 | grad norm: 6.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       21/     400 | consumed samples:          168 | elapsed time per iteration (ms): 2396.9 | learning rate: 9.724E-06 | global batch size:     8 | lm loss: 6.120697E+00 | loss scale: 1.0 | grad norm: 23.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       22/     400 | consumed samples:          176 | elapsed time per iteration (ms): 1585.8 | learning rate: 9.701E-06 | global batch size:     8 | lm loss: 6.019697E+00 | loss scale: 1.0 | grad norm: 4.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       23/     400 | consumed samples:          184 | elapsed time per iteration (ms): 1436.7 | learning rate: 9.678E-06 | global batch size:     8 | lm loss: 5.988437E+00 | loss scale: 1.0 | grad norm: 5.166 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       24/     400 | consumed samples:          192 | elapsed time per iteration (ms): 2451.9 | learning rate: 9.655E-06 | global batch size:     8 | lm loss: 5.697437E+00 | loss scale: 1.0 | grad norm: 5.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       25/     400 | consumed samples:          200 | elapsed time per iteration (ms): 1589.2 | learning rate: 9.632E-06 | global batch size:     8 | lm loss: 5.932370E+00 | loss scale: 1.0 | grad norm: 6.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       26/     400 | consumed samples:          208 | elapsed time per iteration (ms): 2400.6 | learning rate: 9.609E-06 | global batch size:     8 | lm loss: 5.846738E+00 | loss scale: 1.0 | grad norm: 5.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       27/     400 | consumed samples:          216 | elapsed time per iteration (ms): 2462.9 | learning rate: 9.586E-06 | global batch size:     8 | lm loss: 5.799790E+00 | loss scale: 1.0 | grad norm: 4.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       28/     400 | consumed samples:          224 | elapsed time per iteration (ms): 1559.7 | learning rate: 9.563E-06 | global batch size:     8 | lm loss: 5.905821E+00 | loss scale: 1.0 | grad norm: 6.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       29/     400 | consumed samples:          232 | elapsed time per iteration (ms): 2443.4 | learning rate: 9.540E-06 | global batch size:     8 | lm loss: 5.858024E+00 | loss scale: 1.0 | grad norm: 4.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       30/     400 | consumed samples:          240 | elapsed time per iteration (ms): 1493.0 | learning rate: 9.517E-06 | global batch size:     8 | lm loss: 6.122587E+00 | loss scale: 1.0 | grad norm: 6.377 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       31/     400 | consumed samples:          248 | elapsed time per iteration (ms): 2350.6 | learning rate: 9.494E-06 | global batch size:     8 | lm loss: 5.938609E+00 | loss scale: 1.0 | grad norm: 5.278 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       32/     400 | consumed samples:          256 | elapsed time per iteration (ms): 1497.7 | learning rate: 9.471E-06 | global batch size:     8 | lm loss: 5.781454E+00 | loss scale: 1.0 | grad norm: 5.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       33/     400 | consumed samples:          264 | elapsed time per iteration (ms): 2453.6 | learning rate: 9.448E-06 | global batch size:     8 | lm loss: 5.827174E+00 | loss scale: 1.0 | grad norm: 5.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       34/     400 | consumed samples:          272 | elapsed time per iteration (ms): 1545.1 | learning rate: 9.425E-06 | global batch size:     8 | lm loss: 5.999476E+00 | loss scale: 1.0 | grad norm: 4.263 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       35/     400 | consumed samples:          280 | elapsed time per iteration (ms): 2412.0 | learning rate: 9.402E-06 | global batch size:     8 | lm loss: 5.951681E+00 | loss scale: 1.0 | grad norm: 13.127 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       36/     400 | consumed samples:          288 | elapsed time per iteration (ms): 2559.4 | learning rate: 9.379E-06 | global batch size:     8 | lm loss: 5.795689E+00 | loss scale: 1.0 | grad norm: 7.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       37/     400 | consumed samples:          296 | elapsed time per iteration (ms): 2538.0 | learning rate: 9.355E-06 | global batch size:     8 | lm loss: 5.928599E+00 | loss scale: 1.0 | grad norm: 5.203 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       38/     400 | consumed samples:          304 | elapsed time per iteration (ms): 2445.4 | learning rate: 9.332E-06 | global batch size:     8 | lm loss: 5.773735E+00 | loss scale: 1.0 | grad norm: 5.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       39/     400 | consumed samples:          312 | elapsed time per iteration (ms): 2332.8 | learning rate: 9.309E-06 | global batch size:     8 | lm loss: 5.816530E+00 | loss scale: 1.0 | grad norm: 9.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       40/     400 | consumed samples:          320 | elapsed time per iteration (ms): 2477.1 | learning rate: 9.286E-06 | global batch size:     8 | lm loss: 6.079061E+00 | loss scale: 1.0 | grad norm: 8.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       41/     400 | consumed samples:          328 | elapsed time per iteration (ms): 2385.3 | learning rate: 9.263E-06 | global batch size:     8 | lm loss: 5.771598E+00 | loss scale: 1.0 | grad norm: 4.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       42/     400 | consumed samples:          336 | elapsed time per iteration (ms): 2426.8 | learning rate: 9.240E-06 | global batch size:     8 | lm loss: 5.798909E+00 | loss scale: 1.0 | grad norm: 5.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       43/     400 | consumed samples:          344 | elapsed time per iteration (ms): 1582.0 | learning rate: 9.217E-06 | global batch size:     8 | lm loss: 5.661469E+00 | loss scale: 1.0 | grad norm: 4.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       44/     400 | consumed samples:          352 | elapsed time per iteration (ms): 3303.7 | learning rate: 9.194E-06 | global batch size:     8 | lm loss: 5.831503E+00 | loss scale: 1.0 | grad norm: 3.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       45/     400 | consumed samples:          360 | elapsed time per iteration (ms): 2390.8 | learning rate: 9.171E-06 | global batch size:     8 | lm loss: 5.970099E+00 | loss scale: 1.0 | grad norm: 7.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       46/     400 | consumed samples:          368 | elapsed time per iteration (ms): 2422.4 | learning rate: 9.148E-06 | global batch size:     8 | lm loss: 6.023202E+00 | loss scale: 1.0 | grad norm: 3.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       47/     400 | consumed samples:          376 | elapsed time per iteration (ms): 2394.2 | learning rate: 9.125E-06 | global batch size:     8 | lm loss: 5.866337E+00 | loss scale: 1.0 | grad norm: 4.233 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       48/     400 | consumed samples:          384 | elapsed time per iteration (ms): 1485.9 | learning rate: 9.102E-06 | global batch size:     8 | lm loss: 5.964726E+00 | loss scale: 1.0 | grad norm: 4.061 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       49/     400 | consumed samples:          392 | elapsed time per iteration (ms): 1510.9 | learning rate: 9.079E-06 | global batch size:     8 | lm loss: 5.917276E+00 | loss scale: 1.0 | grad norm: 5.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       50/     400 | consumed samples:          400 | elapsed time per iteration (ms): 2326.5 | learning rate: 9.056E-06 | global batch size:     8 | lm loss: 5.978957E+00 | loss scale: 1.0 | grad norm: 4.540 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       51/     400 | consumed samples:          408 | elapsed time per iteration (ms): 1490.9 | learning rate: 9.033E-06 | global batch size:     8 | lm loss: 5.718536E+00 | loss scale: 1.0 | grad norm: 6.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       52/     400 | consumed samples:          416 | elapsed time per iteration (ms): 2500.1 | learning rate: 9.010E-06 | global batch size:     8 | lm loss: 5.944783E+00 | loss scale: 1.0 | grad norm: 4.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       53/     400 | consumed samples:          424 | elapsed time per iteration (ms): 1500.3 | learning rate: 8.987E-06 | global batch size:     8 | lm loss: 5.881502E+00 | loss scale: 1.0 | grad norm: 6.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       54/     400 | consumed samples:          432 | elapsed time per iteration (ms): 2468.2 | learning rate: 8.964E-06 | global batch size:     8 | lm loss: 5.899101E+00 | loss scale: 1.0 | grad norm: 5.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       55/     400 | consumed samples:          440 | elapsed time per iteration (ms): 2397.7 | learning rate: 8.941E-06 | global batch size:     8 | lm loss: 5.568121E+00 | loss scale: 1.0 | grad norm: 3.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       56/     400 | consumed samples:          448 | elapsed time per iteration (ms): 1502.3 | learning rate: 8.918E-06 | global batch size:     8 | lm loss: 5.750298E+00 | loss scale: 1.0 | grad norm: 3.379 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       57/     400 | consumed samples:          456 | elapsed time per iteration (ms): 2420.1 | learning rate: 8.895E-06 | global batch size:     8 | lm loss: 5.921292E+00 | loss scale: 1.0 | grad norm: 4.201 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       58/     400 | consumed samples:          464 | elapsed time per iteration (ms): 3379.6 | learning rate: 8.872E-06 | global batch size:     8 | lm loss: 5.954576E+00 | loss scale: 1.0 | grad norm: 6.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       59/     400 | consumed samples:          472 | elapsed time per iteration (ms): 1599.4 | learning rate: 8.849E-06 | global batch size:     8 | lm loss: 6.001891E+00 | loss scale: 1.0 | grad norm: 9.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       60/     400 | consumed samples:          480 | elapsed time per iteration (ms): 2321.9 | learning rate: 8.826E-06 | global batch size:     8 | lm loss: 5.851727E+00 | loss scale: 1.0 | grad norm: 4.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       61/     400 | consumed samples:          488 | elapsed time per iteration (ms): 3315.9 | learning rate: 8.803E-06 | global batch size:     8 | lm loss: 5.667913E+00 | loss scale: 1.0 | grad norm: 3.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       62/     400 | consumed samples:          496 | elapsed time per iteration (ms): 2359.9 | learning rate: 8.780E-06 | global batch size:     8 | lm loss: 5.680753E+00 | loss scale: 1.0 | grad norm: 3.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       63/     400 | consumed samples:          504 | elapsed time per iteration (ms): 1501.3 | learning rate: 8.757E-06 | global batch size:     8 | lm loss: 5.759861E+00 | loss scale: 1.0 | grad norm: 4.317 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       64/     400 | consumed samples:          512 | elapsed time per iteration (ms): 1443.2 | learning rate: 8.734E-06 | global batch size:     8 | lm loss: 5.683595E+00 | loss scale: 1.0 | grad norm: 5.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       65/     400 | consumed samples:          520 | elapsed time per iteration (ms): 1508.9 | learning rate: 8.711E-06 | global batch size:     8 | lm loss: 5.667119E+00 | loss scale: 1.0 | grad norm: 3.544 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       66/     400 | consumed samples:          528 | elapsed time per iteration (ms): 2372.9 | learning rate: 8.688E-06 | global batch size:     8 | lm loss: 5.601396E+00 | loss scale: 1.0 | grad norm: 3.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       67/     400 | consumed samples:          536 | elapsed time per iteration (ms): 1474.7 | learning rate: 8.665E-06 | global batch size:     8 | lm loss: 5.758937E+00 | loss scale: 1.0 | grad norm: 7.316 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       68/     400 | consumed samples:          544 | elapsed time per iteration (ms): 1495.6 | learning rate: 8.642E-06 | global batch size:     8 | lm loss: 5.544774E+00 | loss scale: 1.0 | grad norm: 3.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       69/     400 | consumed samples:          552 | elapsed time per iteration (ms): 2346.3 | learning rate: 8.619E-06 | global batch size:     8 | lm loss: 5.794197E+00 | loss scale: 1.0 | grad norm: 5.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       70/     400 | consumed samples:          560 | elapsed time per iteration (ms): 2298.4 | learning rate: 8.596E-06 | global batch size:     8 | lm loss: 5.588172E+00 | loss scale: 1.0 | grad norm: 7.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       71/     400 | consumed samples:          568 | elapsed time per iteration (ms): 2494.1 | learning rate: 8.573E-06 | global batch size:     8 | lm loss: 5.746605E+00 | loss scale: 1.0 | grad norm: 3.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       72/     400 | consumed samples:          576 | elapsed time per iteration (ms): 1464.9 | learning rate: 8.550E-06 | global batch size:     8 | lm loss: 5.759345E+00 | loss scale: 1.0 | grad norm: 6.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       73/     400 | consumed samples:          584 | elapsed time per iteration (ms): 2400.0 | learning rate: 8.527E-06 | global batch size:     8 | lm loss: 5.766779E+00 | loss scale: 1.0 | grad norm: 3.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       74/     400 | consumed samples:          592 | elapsed time per iteration (ms): 2335.8 | learning rate: 8.504E-06 | global batch size:     8 | lm loss: 5.993175E+00 | loss scale: 1.0 | grad norm: 4.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       75/     400 | consumed samples:          600 | elapsed time per iteration (ms): 2393.1 | learning rate: 8.481E-06 | global batch size:     8 | lm loss: 5.585943E+00 | loss scale: 1.0 | grad norm: 3.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       76/     400 | consumed samples:          608 | elapsed time per iteration (ms): 1475.3 | learning rate: 8.458E-06 | global batch size:     8 | lm loss: 5.948744E+00 | loss scale: 1.0 | grad norm: 4.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       77/     400 | consumed samples:          616 | elapsed time per iteration (ms): 2395.0 | learning rate: 8.435E-06 | global batch size:     8 | lm loss: 5.790004E+00 | loss scale: 1.0 | grad norm: 4.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       78/     400 | consumed samples:          624 | elapsed time per iteration (ms): 1497.3 | learning rate: 8.412E-06 | global batch size:     8 | lm loss: 5.928574E+00 | loss scale: 1.0 | grad norm: 3.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       79/     400 | consumed samples:          632 | elapsed time per iteration (ms): 2399.8 | learning rate: 8.389E-06 | global batch size:     8 | lm loss: 5.744474E+00 | loss scale: 1.0 | grad norm: 6.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       80/     400 | consumed samples:          640 | elapsed time per iteration (ms): 1554.2 | learning rate: 8.366E-06 | global batch size:     8 | lm loss: 5.696903E+00 | loss scale: 1.0 | grad norm: 4.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       81/     400 | consumed samples:          648 | elapsed time per iteration (ms): 1474.7 | learning rate: 8.343E-06 | global batch size:     8 | lm loss: 5.891483E+00 | loss scale: 1.0 | grad norm: 8.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       82/     400 | consumed samples:          656 | elapsed time per iteration (ms): 3376.4 | learning rate: 8.320E-06 | global batch size:     8 | lm loss: 5.999062E+00 | loss scale: 1.0 | grad norm: 4.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       83/     400 | consumed samples:          664 | elapsed time per iteration (ms): 1435.1 | learning rate: 8.297E-06 | global batch size:     8 | lm loss: 5.510583E+00 | loss scale: 1.0 | grad norm: 3.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       84/     400 | consumed samples:          672 | elapsed time per iteration (ms): 1464.6 | learning rate: 8.274E-06 | global batch size:     8 | lm loss: 5.818900E+00 | loss scale: 1.0 | grad norm: 3.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       85/     400 | consumed samples:          680 | elapsed time per iteration (ms): 2396.7 | learning rate: 8.251E-06 | global batch size:     8 | lm loss: 5.968085E+00 | loss scale: 1.0 | grad norm: 4.146 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       86/     400 | consumed samples:          688 | elapsed time per iteration (ms): 1500.0 | learning rate: 8.228E-06 | global batch size:     8 | lm loss: 5.771859E+00 | loss scale: 1.0 | grad norm: 4.368 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       87/     400 | consumed samples:          696 | elapsed time per iteration (ms): 2340.7 | learning rate: 8.205E-06 | global batch size:     8 | lm loss: 5.768809E+00 | loss scale: 1.0 | grad norm: 4.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       88/     400 | consumed samples:          704 | elapsed time per iteration (ms): 1458.6 | learning rate: 8.182E-06 | global batch size:     8 | lm loss: 5.726015E+00 | loss scale: 1.0 | grad norm: 5.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       89/     400 | consumed samples:          712 | elapsed time per iteration (ms): 1545.4 | learning rate: 8.159E-06 | global batch size:     8 | lm loss: 5.831830E+00 | loss scale: 1.0 | grad norm: 3.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       90/     400 | consumed samples:          720 | elapsed time per iteration (ms): 1554.5 | learning rate: 8.136E-06 | global batch size:     8 | lm loss: 5.876579E+00 | loss scale: 1.0 | grad norm: 4.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       91/     400 | consumed samples:          728 | elapsed time per iteration (ms): 1463.7 | learning rate: 8.113E-06 | global batch size:     8 | lm loss: 5.675472E+00 | loss scale: 1.0 | grad norm: 3.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       92/     400 | consumed samples:          736 | elapsed time per iteration (ms): 1538.5 | learning rate: 8.090E-06 | global batch size:     8 | lm loss: 5.652137E+00 | loss scale: 1.0 | grad norm: 3.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       93/     400 | consumed samples:          744 | elapsed time per iteration (ms): 2334.3 | learning rate: 8.066E-06 | global batch size:     8 | lm loss: 5.877266E+00 | loss scale: 1.0 | grad norm: 5.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       94/     400 | consumed samples:          752 | elapsed time per iteration (ms): 1477.8 | learning rate: 8.043E-06 | global batch size:     8 | lm loss: 5.793442E+00 | loss scale: 1.0 | grad norm: 3.262 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       95/     400 | consumed samples:          760 | elapsed time per iteration (ms): 1483.6 | learning rate: 8.020E-06 | global batch size:     8 | lm loss: 5.985808E+00 | loss scale: 1.0 | grad norm: 4.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       96/     400 | consumed samples:          768 | elapsed time per iteration (ms): 1447.0 | learning rate: 7.997E-06 | global batch size:     8 | lm loss: 6.043246E+00 | loss scale: 1.0 | grad norm: 6.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       97/     400 | consumed samples:          776 | elapsed time per iteration (ms): 1452.2 | learning rate: 7.974E-06 | global batch size:     8 | lm loss: 5.867172E+00 | loss scale: 1.0 | grad norm: 5.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       98/     400 | consumed samples:          784 | elapsed time per iteration (ms): 1502.4 | learning rate: 7.951E-06 | global batch size:     8 | lm loss: 5.644014E+00 | loss scale: 1.0 | grad norm: 4.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       99/     400 | consumed samples:          792 | elapsed time per iteration (ms): 2315.2 | learning rate: 7.928E-06 | global batch size:     8 | lm loss: 5.779724E+00 | loss scale: 1.0 | grad norm: 6.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      100/     400 | consumed samples:          800 | elapsed time per iteration (ms): 3408.8 | learning rate: 7.905E-06 | global batch size:     8 | lm loss: 5.941589E+00 | loss scale: 1.0 | grad norm: 4.327 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      101/     400 | consumed samples:          808 | elapsed time per iteration (ms): 2375.1 | learning rate: 7.882E-06 | global batch size:     8 | lm loss: 5.888847E+00 | loss scale: 1.0 | grad norm: 28.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      102/     400 | consumed samples:          816 | elapsed time per iteration (ms): 1497.7 | learning rate: 7.859E-06 | global batch size:     8 | lm loss: 5.803658E+00 | loss scale: 1.0 | grad norm: 5.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      103/     400 | consumed samples:          824 | elapsed time per iteration (ms): 2957.7 | learning rate: 7.836E-06 | global batch size:     8 | lm loss: 5.900291E+00 | loss scale: 1.0 | grad norm: 7.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      104/     400 | consumed samples:          832 | elapsed time per iteration (ms): 2353.2 | learning rate: 7.813E-06 | global batch size:     8 | lm loss: 5.747166E+00 | loss scale: 1.0 | grad norm: 4.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      105/     400 | consumed samples:          840 | elapsed time per iteration (ms): 2440.0 | learning rate: 7.790E-06 | global batch size:     8 | lm loss: 5.658850E+00 | loss scale: 1.0 | grad norm: 3.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      106/     400 | consumed samples:          848 | elapsed time per iteration (ms): 1482.2 | learning rate: 7.767E-06 | global batch size:     8 | lm loss: 5.655137E+00 | loss scale: 1.0 | grad norm: 3.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      107/     400 | consumed samples:          856 | elapsed time per iteration (ms): 2466.5 | learning rate: 7.744E-06 | global batch size:     8 | lm loss: 5.592999E+00 | loss scale: 1.0 | grad norm: 21.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      108/     400 | consumed samples:          864 | elapsed time per iteration (ms): 2399.8 | learning rate: 7.721E-06 | global batch size:     8 | lm loss: 5.721118E+00 | loss scale: 1.0 | grad norm: 5.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      109/     400 | consumed samples:          872 | elapsed time per iteration (ms): 1501.8 | learning rate: 7.698E-06 | global batch size:     8 | lm loss: 5.778303E+00 | loss scale: 1.0 | grad norm: 3.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      110/     400 | consumed samples:          880 | elapsed time per iteration (ms): 1500.4 | learning rate: 7.675E-06 | global batch size:     8 | lm loss: 6.081213E+00 | loss scale: 1.0 | grad norm: 4.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      111/     400 | consumed samples:          888 | elapsed time per iteration (ms): 2399.4 | learning rate: 7.652E-06 | global batch size:     8 | lm loss: 5.795794E+00 | loss scale: 1.0 | grad norm: 5.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      112/     400 | consumed samples:          896 | elapsed time per iteration (ms): 1499.9 | learning rate: 7.629E-06 | global batch size:     8 | lm loss: 5.713007E+00 | loss scale: 1.0 | grad norm: 4.317 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      113/     400 | consumed samples:          904 | elapsed time per iteration (ms): 2415.5 | learning rate: 7.606E-06 | global batch size:     8 | lm loss: 5.539949E+00 | loss scale: 1.0 | grad norm: 7.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      114/     400 | consumed samples:          912 | elapsed time per iteration (ms): 2414.1 | learning rate: 7.583E-06 | global batch size:     8 | lm loss: 6.013778E+00 | loss scale: 1.0 | grad norm: 3.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      115/     400 | consumed samples:          920 | elapsed time per iteration (ms): 1466.8 | learning rate: 7.560E-06 | global batch size:     8 | lm loss: 5.693854E+00 | loss scale: 1.0 | grad norm: 4.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      116/     400 | consumed samples:          928 | elapsed time per iteration (ms): 1503.3 | learning rate: 7.537E-06 | global batch size:     8 | lm loss: 5.663584E+00 | loss scale: 1.0 | grad norm: 3.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      117/     400 | consumed samples:          936 | elapsed time per iteration (ms): 1461.6 | learning rate: 7.514E-06 | global batch size:     8 | lm loss: 5.691365E+00 | loss scale: 1.0 | grad norm: 13.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      118/     400 | consumed samples:          944 | elapsed time per iteration (ms): 1441.7 | learning rate: 7.491E-06 | global batch size:     8 | lm loss: 6.045256E+00 | loss scale: 1.0 | grad norm: 4.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      119/     400 | consumed samples:          952 | elapsed time per iteration (ms): 2325.2 | learning rate: 7.468E-06 | global batch size:     8 | lm loss: 5.545451E+00 | loss scale: 1.0 | grad norm: 3.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      120/     400 | consumed samples:          960 | elapsed time per iteration (ms): 1484.3 | learning rate: 7.445E-06 | global batch size:     8 | lm loss: 5.870438E+00 | loss scale: 1.0 | grad norm: 6.553 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      121/     400 | consumed samples:          968 | elapsed time per iteration (ms): 2297.3 | learning rate: 7.422E-06 | global batch size:     8 | lm loss: 5.802597E+00 | loss scale: 1.0 | grad norm: 4.160 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      122/     400 | consumed samples:          976 | elapsed time per iteration (ms): 1495.1 | learning rate: 7.399E-06 | global batch size:     8 | lm loss: 5.701596E+00 | loss scale: 1.0 | grad norm: 4.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      123/     400 | consumed samples:          984 | elapsed time per iteration (ms): 2390.7 | learning rate: 7.376E-06 | global batch size:     8 | lm loss: 5.803273E+00 | loss scale: 1.0 | grad norm: 4.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      124/     400 | consumed samples:          992 | elapsed time per iteration (ms): 2435.5 | learning rate: 7.353E-06 | global batch size:     8 | lm loss: 5.810572E+00 | loss scale: 1.0 | grad norm: 7.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      125/     400 | consumed samples:         1000 | elapsed time per iteration (ms): 2400.5 | learning rate: 7.330E-06 | global batch size:     8 | lm loss: 5.717497E+00 | loss scale: 1.0 | grad norm: 3.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      126/     400 | consumed samples:         1008 | elapsed time per iteration (ms): 1492.2 | learning rate: 7.307E-06 | global batch size:     8 | lm loss: 5.622764E+00 | loss scale: 1.0 | grad norm: 6.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      127/     400 | consumed samples:         1016 | elapsed time per iteration (ms): 1472.3 | learning rate: 7.284E-06 | global batch size:     8 | lm loss: 5.904377E+00 | loss scale: 1.0 | grad norm: 6.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      128/     400 | consumed samples:         1024 | elapsed time per iteration (ms): 2343.5 | learning rate: 7.261E-06 | global batch size:     8 | lm loss: 5.769310E+00 | loss scale: 1.0 | grad norm: 4.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      129/     400 | consumed samples:         1032 | elapsed time per iteration (ms): 1475.6 | learning rate: 7.238E-06 | global batch size:     8 | lm loss: 5.617837E+00 | loss scale: 1.0 | grad norm: 5.380 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      130/     400 | consumed samples:         1040 | elapsed time per iteration (ms): 2381.2 | learning rate: 7.215E-06 | global batch size:     8 | lm loss: 6.073754E+00 | loss scale: 1.0 | grad norm: 5.279 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      131/     400 | consumed samples:         1048 | elapsed time per iteration (ms): 3404.3 | learning rate: 7.192E-06 | global batch size:     8 | lm loss: 5.649523E+00 | loss scale: 1.0 | grad norm: 3.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      132/     400 | consumed samples:         1056 | elapsed time per iteration (ms): 1450.6 | learning rate: 7.169E-06 | global batch size:     8 | lm loss: 5.870903E+00 | loss scale: 1.0 | grad norm: 3.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      133/     400 | consumed samples:         1064 | elapsed time per iteration (ms): 1477.7 | learning rate: 7.146E-06 | global batch size:     8 | lm loss: 5.700963E+00 | loss scale: 1.0 | grad norm: 5.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      134/     400 | consumed samples:         1072 | elapsed time per iteration (ms): 1472.9 | learning rate: 7.123E-06 | global batch size:     8 | lm loss: 5.787673E+00 | loss scale: 1.0 | grad norm: 10.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      135/     400 | consumed samples:         1080 | elapsed time per iteration (ms): 2395.5 | learning rate: 7.100E-06 | global batch size:     8 | lm loss: 5.761534E+00 | loss scale: 1.0 | grad norm: 3.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      136/     400 | consumed samples:         1088 | elapsed time per iteration (ms): 1509.9 | learning rate: 7.077E-06 | global batch size:     8 | lm loss: 5.826005E+00 | loss scale: 1.0 | grad norm: 4.576 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      137/     400 | consumed samples:         1096 | elapsed time per iteration (ms): 1504.3 | learning rate: 7.054E-06 | global batch size:     8 | lm loss: 5.891942E+00 | loss scale: 1.0 | grad norm: 6.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      138/     400 | consumed samples:         1104 | elapsed time per iteration (ms): 1484.6 | learning rate: 7.031E-06 | global batch size:     8 | lm loss: 5.712693E+00 | loss scale: 1.0 | grad norm: 8.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      139/     400 | consumed samples:         1112 | elapsed time per iteration (ms): 2329.4 | learning rate: 7.008E-06 | global batch size:     8 | lm loss: 5.747948E+00 | loss scale: 1.0 | grad norm: 3.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      140/     400 | consumed samples:         1120 | elapsed time per iteration (ms): 2337.4 | learning rate: 6.985E-06 | global batch size:     8 | lm loss: 5.718904E+00 | loss scale: 1.0 | grad norm: 31.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      141/     400 | consumed samples:         1128 | elapsed time per iteration (ms): 1533.6 | learning rate: 6.962E-06 | global batch size:     8 | lm loss: 5.716838E+00 | loss scale: 1.0 | grad norm: 4.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      142/     400 | consumed samples:         1136 | elapsed time per iteration (ms): 1497.4 | learning rate: 6.939E-06 | global batch size:     8 | lm loss: 5.524399E+00 | loss scale: 1.0 | grad norm: 3.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      143/     400 | consumed samples:         1144 | elapsed time per iteration (ms): 2402.1 | learning rate: 6.916E-06 | global batch size:     8 | lm loss: 5.593142E+00 | loss scale: 1.0 | grad norm: 3.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      144/     400 | consumed samples:         1152 | elapsed time per iteration (ms): 1495.5 | learning rate: 6.893E-06 | global batch size:     8 | lm loss: 5.684685E+00 | loss scale: 1.0 | grad norm: 3.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      145/     400 | consumed samples:         1160 | elapsed time per iteration (ms): 2310.9 | learning rate: 6.870E-06 | global batch size:     8 | lm loss: 5.713470E+00 | loss scale: 1.0 | grad norm: 24.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      146/     400 | consumed samples:         1168 | elapsed time per iteration (ms): 1489.3 | learning rate: 6.847E-06 | global batch size:     8 | lm loss: 6.248825E+00 | loss scale: 1.0 | grad norm: 34.061 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      147/     400 | consumed samples:         1176 | elapsed time per iteration (ms): 1423.2 | learning rate: 6.824E-06 | global batch size:     8 | lm loss: 5.714531E+00 | loss scale: 1.0 | grad norm: 3.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      148/     400 | consumed samples:         1184 | elapsed time per iteration (ms): 1501.6 | learning rate: 6.801E-06 | global batch size:     8 | lm loss: 5.660373E+00 | loss scale: 1.0 | grad norm: 5.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      149/     400 | consumed samples:         1192 | elapsed time per iteration (ms): 1478.2 | learning rate: 6.777E-06 | global batch size:     8 | lm loss: 5.810618E+00 | loss scale: 1.0 | grad norm: 3.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      150/     400 | consumed samples:         1200 | elapsed time per iteration (ms): 1438.9 | learning rate: 6.754E-06 | global batch size:     8 | lm loss: 5.787215E+00 | loss scale: 1.0 | grad norm: 4.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      151/     400 | consumed samples:         1208 | elapsed time per iteration (ms): 2961.8 | learning rate: 6.731E-06 | global batch size:     8 | lm loss: 5.734316E+00 | loss scale: 1.0 | grad norm: 4.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      152/     400 | consumed samples:         1216 | elapsed time per iteration (ms): 3298.8 | learning rate: 6.708E-06 | global batch size:     8 | lm loss: 5.819350E+00 | loss scale: 1.0 | grad norm: 28.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      153/     400 | consumed samples:         1224 | elapsed time per iteration (ms): 1497.9 | learning rate: 6.685E-06 | global batch size:     8 | lm loss: 6.005525E+00 | loss scale: 1.0 | grad norm: 4.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      154/     400 | consumed samples:         1232 | elapsed time per iteration (ms): 2414.6 | learning rate: 6.662E-06 | global batch size:     8 | lm loss: 5.774727E+00 | loss scale: 1.0 | grad norm: 3.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      155/     400 | consumed samples:         1240 | elapsed time per iteration (ms): 1451.2 | learning rate: 6.639E-06 | global batch size:     8 | lm loss: 5.843771E+00 | loss scale: 1.0 | grad norm: 4.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      156/     400 | consumed samples:         1248 | elapsed time per iteration (ms): 1497.0 | learning rate: 6.616E-06 | global batch size:     8 | lm loss: 5.844837E+00 | loss scale: 1.0 | grad norm: 3.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      157/     400 | consumed samples:         1256 | elapsed time per iteration (ms): 2336.8 | learning rate: 6.593E-06 | global batch size:     8 | lm loss: 5.711819E+00 | loss scale: 1.0 | grad norm: 127.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      158/     400 | consumed samples:         1264 | elapsed time per iteration (ms): 2302.8 | learning rate: 6.570E-06 | global batch size:     8 | lm loss: 5.658978E+00 | loss scale: 1.0 | grad norm: 6.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      159/     400 | consumed samples:         1272 | elapsed time per iteration (ms): 1496.9 | learning rate: 6.547E-06 | global batch size:     8 | lm loss: 6.176419E+00 | loss scale: 1.0 | grad norm: 4.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      160/     400 | consumed samples:         1280 | elapsed time per iteration (ms): 1437.4 | learning rate: 6.524E-06 | global batch size:     8 | lm loss: 5.666178E+00 | loss scale: 1.0 | grad norm: 4.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      161/     400 | consumed samples:         1288 | elapsed time per iteration (ms): 1469.4 | learning rate: 6.501E-06 | global batch size:     8 | lm loss: 5.574815E+00 | loss scale: 1.0 | grad norm: 74.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      162/     400 | consumed samples:         1296 | elapsed time per iteration (ms): 1448.4 | learning rate: 6.478E-06 | global batch size:     8 | lm loss: 5.713027E+00 | loss scale: 1.0 | grad norm: 3.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      163/     400 | consumed samples:         1304 | elapsed time per iteration (ms): 1471.1 | learning rate: 6.455E-06 | global batch size:     8 | lm loss: 7.155573E+00 | loss scale: 1.0 | grad norm: 4.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      164/     400 | consumed samples:         1312 | elapsed time per iteration (ms): 2340.9 | learning rate: 6.432E-06 | global batch size:     8 | lm loss: 6.020610E+00 | loss scale: 1.0 | grad norm: 4.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      165/     400 | consumed samples:         1320 | elapsed time per iteration (ms): 1504.8 | learning rate: 6.409E-06 | global batch size:     8 | lm loss: 5.721422E+00 | loss scale: 1.0 | grad norm: 11.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      166/     400 | consumed samples:         1328 | elapsed time per iteration (ms): 1499.2 | learning rate: 6.386E-06 | global batch size:     8 | lm loss: 5.746063E+00 | loss scale: 1.0 | grad norm: 3.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      167/     400 | consumed samples:         1336 | elapsed time per iteration (ms): 1498.8 | learning rate: 6.363E-06 | global batch size:     8 | lm loss: 5.553256E+00 | loss scale: 1.0 | grad norm: 6.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      168/     400 | consumed samples:         1344 | elapsed time per iteration (ms): 1500.6 | learning rate: 6.340E-06 | global batch size:     8 | lm loss: 5.654642E+00 | loss scale: 1.0 | grad norm: 3.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      169/     400 | consumed samples:         1352 | elapsed time per iteration (ms): 1557.9 | learning rate: 6.317E-06 | global batch size:     8 | lm loss: 5.737079E+00 | loss scale: 1.0 | grad norm: 3.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      170/     400 | consumed samples:         1360 | elapsed time per iteration (ms): 1541.5 | learning rate: 6.294E-06 | global batch size:     8 | lm loss: 5.795664E+00 | loss scale: 1.0 | grad norm: 4.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      171/     400 | consumed samples:         1368 | elapsed time per iteration (ms): 2399.9 | learning rate: 6.271E-06 | global batch size:     8 | lm loss: 5.764149E+00 | loss scale: 1.0 | grad norm: 3.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      172/     400 | consumed samples:         1376 | elapsed time per iteration (ms): 1500.7 | learning rate: 6.248E-06 | global batch size:     8 | lm loss: 5.654769E+00 | loss scale: 1.0 | grad norm: 20.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      173/     400 | consumed samples:         1384 | elapsed time per iteration (ms): 2396.9 | learning rate: 6.225E-06 | global batch size:     8 | lm loss: 5.550323E+00 | loss scale: 1.0 | grad norm: 3.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      174/     400 | consumed samples:         1392 | elapsed time per iteration (ms): 1503.8 | learning rate: 6.202E-06 | global batch size:     8 | lm loss: 5.883123E+00 | loss scale: 1.0 | grad norm: 6.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      175/     400 | consumed samples:         1400 | elapsed time per iteration (ms): 1499.6 | learning rate: 6.179E-06 | global batch size:     8 | lm loss: 5.911032E+00 | loss scale: 1.0 | grad norm: 4.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      176/     400 | consumed samples:         1408 | elapsed time per iteration (ms): 1500.2 | learning rate: 6.156E-06 | global batch size:     8 | lm loss: 5.629977E+00 | loss scale: 1.0 | grad norm: 3.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      177/     400 | consumed samples:         1416 | elapsed time per iteration (ms): 2399.0 | learning rate: 6.133E-06 | global batch size:     8 | lm loss: 5.685628E+00 | loss scale: 1.0 | grad norm: 3.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      178/     400 | consumed samples:         1424 | elapsed time per iteration (ms): 1525.5 | learning rate: 6.110E-06 | global batch size:     8 | lm loss: 5.903044E+00 | loss scale: 1.0 | grad norm: 7.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      179/     400 | consumed samples:         1432 | elapsed time per iteration (ms): 1475.4 | learning rate: 6.087E-06 | global batch size:     8 | lm loss: 5.620901E+00 | loss scale: 1.0 | grad norm: 5.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      180/     400 | consumed samples:         1440 | elapsed time per iteration (ms): 1443.1 | learning rate: 6.064E-06 | global batch size:     8 | lm loss: 5.639010E+00 | loss scale: 1.0 | grad norm: 9.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      181/     400 | consumed samples:         1448 | elapsed time per iteration (ms): 1483.3 | learning rate: 6.041E-06 | global batch size:     8 | lm loss: 5.626993E+00 | loss scale: 1.0 | grad norm: 9.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      182/     400 | consumed samples:         1456 | elapsed time per iteration (ms): 1470.8 | learning rate: 6.018E-06 | global batch size:     8 | lm loss: 5.710989E+00 | loss scale: 1.0 | grad norm: 5.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      183/     400 | consumed samples:         1464 | elapsed time per iteration (ms): 1498.6 | learning rate: 5.995E-06 | global batch size:     8 | lm loss: 5.649379E+00 | loss scale: 1.0 | grad norm: 7.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      184/     400 | consumed samples:         1472 | elapsed time per iteration (ms): 1526.8 | learning rate: 5.972E-06 | global batch size:     8 | lm loss: 5.714962E+00 | loss scale: 1.0 | grad norm: 20.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      185/     400 | consumed samples:         1480 | elapsed time per iteration (ms): 1480.6 | learning rate: 5.949E-06 | global batch size:     8 | lm loss: 6.108463E+00 | loss scale: 1.0 | grad norm: 6.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      186/     400 | consumed samples:         1488 | elapsed time per iteration (ms): 1456.7 | learning rate: 5.926E-06 | global batch size:     8 | lm loss: 5.832765E+00 | loss scale: 1.0 | grad norm: 5.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      187/     400 | consumed samples:         1496 | elapsed time per iteration (ms): 2391.3 | learning rate: 5.903E-06 | global batch size:     8 | lm loss: 5.852076E+00 | loss scale: 1.0 | grad norm: 10.192 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      188/     400 | consumed samples:         1504 | elapsed time per iteration (ms): 1468.5 | learning rate: 5.880E-06 | global batch size:     8 | lm loss: 5.811114E+00 | loss scale: 1.0 | grad norm: 5.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      189/     400 | consumed samples:         1512 | elapsed time per iteration (ms): 1487.4 | learning rate: 5.857E-06 | global batch size:     8 | lm loss: 5.838123E+00 | loss scale: 1.0 | grad norm: 10.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      190/     400 | consumed samples:         1520 | elapsed time per iteration (ms): 1507.7 | learning rate: 5.834E-06 | global batch size:     8 | lm loss: 5.858017E+00 | loss scale: 1.0 | grad norm: 5.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      191/     400 | consumed samples:         1528 | elapsed time per iteration (ms): 2381.2 | learning rate: 5.811E-06 | global batch size:     8 | lm loss: 5.820107E+00 | loss scale: 1.0 | grad norm: 4.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      192/     400 | consumed samples:         1536 | elapsed time per iteration (ms): 1506.8 | learning rate: 5.788E-06 | global batch size:     8 | lm loss: 5.730682E+00 | loss scale: 1.0 | grad norm: 3.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      193/     400 | consumed samples:         1544 | elapsed time per iteration (ms): 1500.9 | learning rate: 5.765E-06 | global batch size:     8 | lm loss: 6.010261E+00 | loss scale: 1.0 | grad norm: 3.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      194/     400 | consumed samples:         1552 | elapsed time per iteration (ms): 1499.5 | learning rate: 5.742E-06 | global batch size:     8 | lm loss: 5.645044E+00 | loss scale: 1.0 | grad norm: 8.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      195/     400 | consumed samples:         1560 | elapsed time per iteration (ms): 1492.6 | learning rate: 5.719E-06 | global batch size:     8 | lm loss: 5.706790E+00 | loss scale: 1.0 | grad norm: 26.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      196/     400 | consumed samples:         1568 | elapsed time per iteration (ms): 1497.0 | learning rate: 5.696E-06 | global batch size:     8 | lm loss: 5.652251E+00 | loss scale: 1.0 | grad norm: 6.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      197/     400 | consumed samples:         1576 | elapsed time per iteration (ms): 1502.5 | learning rate: 5.673E-06 | global batch size:     8 | lm loss: 5.648921E+00 | loss scale: 1.0 | grad norm: 8.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      198/     400 | consumed samples:         1584 | elapsed time per iteration (ms): 1499.7 | learning rate: 5.650E-06 | global batch size:     8 | lm loss: 5.765338E+00 | loss scale: 1.0 | grad norm: 5.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      199/     400 | consumed samples:         1592 | elapsed time per iteration (ms): 1497.0 | learning rate: 5.627E-06 | global batch size:     8 | lm loss: 5.723654E+00 | loss scale: 1.0 | grad norm: 13.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      200/     400 | consumed samples:         1600 | elapsed time per iteration (ms): 3302.8 | learning rate: 5.604E-06 | global batch size:     8 | lm loss: 5.655068E+00 | loss scale: 1.0 | grad norm: 12.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      201/     400 | consumed samples:         1608 | elapsed time per iteration (ms): 2313.6 | learning rate: 5.581E-06 | global batch size:     8 | lm loss: 5.574658E+00 | loss scale: 1.0 | grad norm: 3.317 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      202/     400 | consumed samples:         1616 | elapsed time per iteration (ms): 1439.1 | learning rate: 5.558E-06 | global batch size:     8 | lm loss: 5.603085E+00 | loss scale: 1.0 | grad norm: 4.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      203/     400 | consumed samples:         1624 | elapsed time per iteration (ms): 1542.3 | learning rate: 5.535E-06 | global batch size:     8 | lm loss: 5.740403E+00 | loss scale: 1.0 | grad norm: 7.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      204/     400 | consumed samples:         1632 | elapsed time per iteration (ms): 1504.6 | learning rate: 5.512E-06 | global batch size:     8 | lm loss: 5.765557E+00 | loss scale: 1.0 | grad norm: 3.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      205/     400 | consumed samples:         1640 | elapsed time per iteration (ms): 1498.9 | learning rate: 5.488E-06 | global batch size:     8 | lm loss: 6.071841E+00 | loss scale: 1.0 | grad norm: 8.190 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      206/     400 | consumed samples:         1648 | elapsed time per iteration (ms): 1512.3 | learning rate: 5.465E-06 | global batch size:     8 | lm loss: 5.866107E+00 | loss scale: 1.0 | grad norm: 5.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      207/     400 | consumed samples:         1656 | elapsed time per iteration (ms): 2392.3 | learning rate: 5.442E-06 | global batch size:     8 | lm loss: 5.895469E+00 | loss scale: 1.0 | grad norm: 4.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      208/     400 | consumed samples:         1664 | elapsed time per iteration (ms): 1451.5 | learning rate: 5.419E-06 | global batch size:     8 | lm loss: 5.555446E+00 | loss scale: 1.0 | grad norm: 4.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      209/     400 | consumed samples:         1672 | elapsed time per iteration (ms): 1443.3 | learning rate: 5.396E-06 | global batch size:     8 | lm loss: 5.655180E+00 | loss scale: 1.0 | grad norm: 5.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      210/     400 | consumed samples:         1680 | elapsed time per iteration (ms): 1430.7 | learning rate: 5.373E-06 | global batch size:     8 | lm loss: 5.775644E+00 | loss scale: 1.0 | grad norm: 4.216 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      211/     400 | consumed samples:         1688 | elapsed time per iteration (ms): 1482.9 | learning rate: 5.350E-06 | global batch size:     8 | lm loss: 5.693276E+00 | loss scale: 1.0 | grad norm: 5.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      212/     400 | consumed samples:         1696 | elapsed time per iteration (ms): 1482.4 | learning rate: 5.327E-06 | global batch size:     8 | lm loss: 5.822553E+00 | loss scale: 1.0 | grad norm: 4.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      213/     400 | consumed samples:         1704 | elapsed time per iteration (ms): 1502.0 | learning rate: 5.304E-06 | global batch size:     8 | lm loss: 5.712752E+00 | loss scale: 1.0 | grad norm: 3.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      214/     400 | consumed samples:         1712 | elapsed time per iteration (ms): 2399.4 | learning rate: 5.281E-06 | global batch size:     8 | lm loss: 5.589382E+00 | loss scale: 1.0 | grad norm: 3.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      215/     400 | consumed samples:         1720 | elapsed time per iteration (ms): 2348.4 | learning rate: 5.258E-06 | global batch size:     8 | lm loss: 5.455956E+00 | loss scale: 1.0 | grad norm: 7.563 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      216/     400 | consumed samples:         1728 | elapsed time per iteration (ms): 1480.1 | learning rate: 5.235E-06 | global batch size:     8 | lm loss: 6.868269E+00 | loss scale: 1.0 | grad norm: 6.323 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      217/     400 | consumed samples:         1736 | elapsed time per iteration (ms): 2888.3 | learning rate: 5.212E-06 | global batch size:     8 | lm loss: 5.736705E+00 | loss scale: 1.0 | grad norm: 17.175 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      218/     400 | consumed samples:         1744 | elapsed time per iteration (ms): 1507.9 | learning rate: 5.189E-06 | global batch size:     8 | lm loss: 5.772435E+00 | loss scale: 1.0 | grad norm: 5.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      219/     400 | consumed samples:         1752 | elapsed time per iteration (ms): 1474.7 | learning rate: 5.166E-06 | global batch size:     8 | lm loss: 5.828607E+00 | loss scale: 1.0 | grad norm: 4.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      220/     400 | consumed samples:         1760 | elapsed time per iteration (ms): 1428.7 | learning rate: 5.143E-06 | global batch size:     8 | lm loss: 5.763588E+00 | loss scale: 1.0 | grad norm: 5.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      221/     400 | consumed samples:         1768 | elapsed time per iteration (ms): 1471.0 | learning rate: 5.120E-06 | global batch size:     8 | lm loss: 5.919618E+00 | loss scale: 1.0 | grad norm: 7.108 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      222/     400 | consumed samples:         1776 | elapsed time per iteration (ms): 1502.2 | learning rate: 5.097E-06 | global batch size:     8 | lm loss: 5.780684E+00 | loss scale: 1.0 | grad norm: 5.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      223/     400 | consumed samples:         1784 | elapsed time per iteration (ms): 1427.0 | learning rate: 5.074E-06 | global batch size:     8 | lm loss: 5.776374E+00 | loss scale: 1.0 | grad norm: 3.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      224/     400 | consumed samples:         1792 | elapsed time per iteration (ms): 1496.0 | learning rate: 5.051E-06 | global batch size:     8 | lm loss: 5.721179E+00 | loss scale: 1.0 | grad norm: 3.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      225/     400 | consumed samples:         1800 | elapsed time per iteration (ms): 1472.4 | learning rate: 5.028E-06 | global batch size:     8 | lm loss: 5.618602E+00 | loss scale: 1.0 | grad norm: 3.370 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      226/     400 | consumed samples:         1808 | elapsed time per iteration (ms): 1445.5 | learning rate: 5.005E-06 | global batch size:     8 | lm loss: 5.591642E+00 | loss scale: 1.0 | grad norm: 3.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      227/     400 | consumed samples:         1816 | elapsed time per iteration (ms): 1504.4 | learning rate: 4.982E-06 | global batch size:     8 | lm loss: 6.065776E+00 | loss scale: 1.0 | grad norm: 4.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      228/     400 | consumed samples:         1824 | elapsed time per iteration (ms): 1464.6 | learning rate: 4.959E-06 | global batch size:     8 | lm loss: 5.953484E+00 | loss scale: 1.0 | grad norm: 4.295 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      229/     400 | consumed samples:         1832 | elapsed time per iteration (ms): 1502.9 | learning rate: 4.936E-06 | global batch size:     8 | lm loss: 5.553235E+00 | loss scale: 1.0 | grad norm: 3.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      230/     400 | consumed samples:         1840 | elapsed time per iteration (ms): 1498.6 | learning rate: 4.913E-06 | global batch size:     8 | lm loss: 5.598457E+00 | loss scale: 1.0 | grad norm: 3.331 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      231/     400 | consumed samples:         1848 | elapsed time per iteration (ms): 1486.0 | learning rate: 4.890E-06 | global batch size:     8 | lm loss: 5.697673E+00 | loss scale: 1.0 | grad norm: 4.334 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      232/     400 | consumed samples:         1856 | elapsed time per iteration (ms): 1448.5 | learning rate: 4.867E-06 | global batch size:     8 | lm loss: 5.960469E+00 | loss scale: 1.0 | grad norm: 4.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      233/     400 | consumed samples:         1864 | elapsed time per iteration (ms): 1453.0 | learning rate: 4.844E-06 | global batch size:     8 | lm loss: 6.321280E+00 | loss scale: 1.0 | grad norm: 9.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      234/     400 | consumed samples:         1872 | elapsed time per iteration (ms): 1499.6 | learning rate: 4.821E-06 | global batch size:     8 | lm loss: 5.862182E+00 | loss scale: 1.0 | grad norm: 7.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      235/     400 | consumed samples:         1880 | elapsed time per iteration (ms): 1451.8 | learning rate: 4.798E-06 | global batch size:     8 | lm loss: 5.542335E+00 | loss scale: 1.0 | grad norm: 10.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      236/     400 | consumed samples:         1888 | elapsed time per iteration (ms): 1487.6 | learning rate: 4.775E-06 | global batch size:     8 | lm loss: 5.751553E+00 | loss scale: 1.0 | grad norm: 5.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      237/     400 | consumed samples:         1896 | elapsed time per iteration (ms): 1485.2 | learning rate: 4.752E-06 | global batch size:     8 | lm loss: 5.991650E+00 | loss scale: 1.0 | grad norm: 5.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      238/     400 | consumed samples:         1904 | elapsed time per iteration (ms): 1474.1 | learning rate: 4.729E-06 | global batch size:     8 | lm loss: 5.945709E+00 | loss scale: 1.0 | grad norm: 5.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      239/     400 | consumed samples:         1912 | elapsed time per iteration (ms): 1500.1 | learning rate: 4.706E-06 | global batch size:     8 | lm loss: 6.031176E+00 | loss scale: 1.0 | grad norm: 7.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      240/     400 | consumed samples:         1920 | elapsed time per iteration (ms): 1458.4 | learning rate: 4.683E-06 | global batch size:     8 | lm loss: 5.685501E+00 | loss scale: 1.0 | grad norm: 3.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      241/     400 | consumed samples:         1928 | elapsed time per iteration (ms): 1440.8 | learning rate: 4.660E-06 | global batch size:     8 | lm loss: 5.603714E+00 | loss scale: 1.0 | grad norm: 4.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      242/     400 | consumed samples:         1936 | elapsed time per iteration (ms): 1453.8 | learning rate: 4.637E-06 | global batch size:     8 | lm loss: 5.832007E+00 | loss scale: 1.0 | grad norm: 3.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      243/     400 | consumed samples:         1944 | elapsed time per iteration (ms): 2346.5 | learning rate: 4.614E-06 | global batch size:     8 | lm loss: 5.614900E+00 | loss scale: 1.0 | grad norm: 16.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      244/     400 | consumed samples:         1952 | elapsed time per iteration (ms): 1443.9 | learning rate: 4.591E-06 | global batch size:     8 | lm loss: 5.672459E+00 | loss scale: 1.0 | grad norm: 11.195 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      245/     400 | consumed samples:         1960 | elapsed time per iteration (ms): 1455.2 | learning rate: 4.568E-06 | global batch size:     8 | lm loss: 5.690286E+00 | loss scale: 1.0 | grad norm: 4.343 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      246/     400 | consumed samples:         1968 | elapsed time per iteration (ms): 1511.7 | learning rate: 4.545E-06 | global batch size:     8 | lm loss: 5.710059E+00 | loss scale: 1.0 | grad norm: 3.553 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      247/     400 | consumed samples:         1976 | elapsed time per iteration (ms): 1486.1 | learning rate: 4.522E-06 | global batch size:     8 | lm loss: 5.636166E+00 | loss scale: 1.0 | grad norm: 3.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      248/     400 | consumed samples:         1984 | elapsed time per iteration (ms): 1503.3 | learning rate: 4.499E-06 | global batch size:     8 | lm loss: 5.709460E+00 | loss scale: 1.0 | grad norm: 5.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      249/     400 | consumed samples:         1992 | elapsed time per iteration (ms): 1449.4 | learning rate: 4.476E-06 | global batch size:     8 | lm loss: 5.576292E+00 | loss scale: 1.0 | grad norm: 4.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      250/     400 | consumed samples:         2000 | elapsed time per iteration (ms): 1446.8 | learning rate: 4.453E-06 | global batch size:     8 | lm loss: 5.814721E+00 | loss scale: 1.0 | grad norm: 4.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      251/     400 | consumed samples:         2008 | elapsed time per iteration (ms): 1464.7 | learning rate: 4.430E-06 | global batch size:     8 | lm loss: 5.712925E+00 | loss scale: 1.0 | grad norm: 5.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      252/     400 | consumed samples:         2016 | elapsed time per iteration (ms): 1534.8 | learning rate: 4.407E-06 | global batch size:     8 | lm loss: 6.072639E+00 | loss scale: 1.0 | grad norm: 4.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      253/     400 | consumed samples:         2024 | elapsed time per iteration (ms): 1444.5 | learning rate: 4.384E-06 | global batch size:     8 | lm loss: 6.136882E+00 | loss scale: 1.0 | grad norm: 4.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      254/     400 | consumed samples:         2032 | elapsed time per iteration (ms): 1460.2 | learning rate: 4.361E-06 | global batch size:     8 | lm loss: 5.783371E+00 | loss scale: 1.0 | grad norm: 5.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      255/     400 | consumed samples:         2040 | elapsed time per iteration (ms): 1437.8 | learning rate: 4.338E-06 | global batch size:     8 | lm loss: 5.622695E+00 | loss scale: 1.0 | grad norm: 14.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      256/     400 | consumed samples:         2048 | elapsed time per iteration (ms): 1477.1 | learning rate: 4.315E-06 | global batch size:     8 | lm loss: 5.589692E+00 | loss scale: 1.0 | grad norm: 7.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      257/     400 | consumed samples:         2056 | elapsed time per iteration (ms): 1489.3 | learning rate: 4.292E-06 | global batch size:     8 | lm loss: 5.911548E+00 | loss scale: 1.0 | grad norm: 3.570 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      258/     400 | consumed samples:         2064 | elapsed time per iteration (ms): 1514.8 | learning rate: 4.269E-06 | global batch size:     8 | lm loss: 5.819646E+00 | loss scale: 1.0 | grad norm: 11.285 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      259/     400 | consumed samples:         2072 | elapsed time per iteration (ms): 1488.8 | learning rate: 4.246E-06 | global batch size:     8 | lm loss: 5.711827E+00 | loss scale: 1.0 | grad norm: 3.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      260/     400 | consumed samples:         2080 | elapsed time per iteration (ms): 1498.3 | learning rate: 4.223E-06 | global batch size:     8 | lm loss: 5.699802E+00 | loss scale: 1.0 | grad norm: 3.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      261/     400 | consumed samples:         2088 | elapsed time per iteration (ms): 1488.5 | learning rate: 4.199E-06 | global batch size:     8 | lm loss: 5.782379E+00 | loss scale: 1.0 | grad norm: 3.351 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      262/     400 | consumed samples:         2096 | elapsed time per iteration (ms): 1499.2 | learning rate: 4.176E-06 | global batch size:     8 | lm loss: 5.694869E+00 | loss scale: 1.0 | grad norm: 4.585 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      263/     400 | consumed samples:         2104 | elapsed time per iteration (ms): 2333.4 | learning rate: 4.153E-06 | global batch size:     8 | lm loss: 5.672031E+00 | loss scale: 1.0 | grad norm: 4.258 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      264/     400 | consumed samples:         2112 | elapsed time per iteration (ms): 1500.2 | learning rate: 4.130E-06 | global batch size:     8 | lm loss: 5.663930E+00 | loss scale: 1.0 | grad norm: 2.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      265/     400 | consumed samples:         2120 | elapsed time per iteration (ms): 1488.6 | learning rate: 4.107E-06 | global batch size:     8 | lm loss: 5.555246E+00 | loss scale: 1.0 | grad norm: 3.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      266/     400 | consumed samples:         2128 | elapsed time per iteration (ms): 1499.4 | learning rate: 4.084E-06 | global batch size:     8 | lm loss: 6.470042E+00 | loss scale: 1.0 | grad norm: 6.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      267/     400 | consumed samples:         2136 | elapsed time per iteration (ms): 1506.2 | learning rate: 4.061E-06 | global batch size:     8 | lm loss: 5.668421E+00 | loss scale: 1.0 | grad norm: 28.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      268/     400 | consumed samples:         2144 | elapsed time per iteration (ms): 1471.7 | learning rate: 4.038E-06 | global batch size:     8 | lm loss: 5.812363E+00 | loss scale: 1.0 | grad norm: 4.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      269/     400 | consumed samples:         2152 | elapsed time per iteration (ms): 1455.1 | learning rate: 4.015E-06 | global batch size:     8 | lm loss: 5.844529E+00 | loss scale: 1.0 | grad norm: 3.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      270/     400 | consumed samples:         2160 | elapsed time per iteration (ms): 1547.0 | learning rate: 3.992E-06 | global batch size:     8 | lm loss: 5.646999E+00 | loss scale: 1.0 | grad norm: 4.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      271/     400 | consumed samples:         2168 | elapsed time per iteration (ms): 1499.5 | learning rate: 3.969E-06 | global batch size:     8 | lm loss: 5.670759E+00 | loss scale: 1.0 | grad norm: 6.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      272/     400 | consumed samples:         2176 | elapsed time per iteration (ms): 1500.2 | learning rate: 3.946E-06 | global batch size:     8 | lm loss: 5.910822E+00 | loss scale: 1.0 | grad norm: 4.237 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      273/     400 | consumed samples:         2184 | elapsed time per iteration (ms): 1451.6 | learning rate: 3.923E-06 | global batch size:     8 | lm loss: 5.886634E+00 | loss scale: 1.0 | grad norm: 3.545 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      274/     400 | consumed samples:         2192 | elapsed time per iteration (ms): 1461.9 | learning rate: 3.900E-06 | global batch size:     8 | lm loss: 5.764914E+00 | loss scale: 1.0 | grad norm: 3.342 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      275/     400 | consumed samples:         2200 | elapsed time per iteration (ms): 1449.0 | learning rate: 3.877E-06 | global batch size:     8 | lm loss: 5.864710E+00 | loss scale: 1.0 | grad norm: 4.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      276/     400 | consumed samples:         2208 | elapsed time per iteration (ms): 1470.5 | learning rate: 3.854E-06 | global batch size:     8 | lm loss: 5.836600E+00 | loss scale: 1.0 | grad norm: 3.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      277/     400 | consumed samples:         2216 | elapsed time per iteration (ms): 1430.2 | learning rate: 3.831E-06 | global batch size:     8 | lm loss: 5.860561E+00 | loss scale: 1.0 | grad norm: 5.553 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      278/     400 | consumed samples:         2224 | elapsed time per iteration (ms): 1487.2 | learning rate: 3.808E-06 | global batch size:     8 | lm loss: 5.924589E+00 | loss scale: 1.0 | grad norm: 4.169 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      279/     400 | consumed samples:         2232 | elapsed time per iteration (ms): 1548.9 | learning rate: 3.785E-06 | global batch size:     8 | lm loss: 5.690161E+00 | loss scale: 1.0 | grad norm: 4.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      280/     400 | consumed samples:         2240 | elapsed time per iteration (ms): 1509.7 | learning rate: 3.762E-06 | global batch size:     8 | lm loss: 5.717653E+00 | loss scale: 1.0 | grad norm: 3.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      281/     400 | consumed samples:         2248 | elapsed time per iteration (ms): 1451.6 | learning rate: 3.739E-06 | global batch size:     8 | lm loss: 5.605825E+00 | loss scale: 1.0 | grad norm: 3.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      282/     400 | consumed samples:         2256 | elapsed time per iteration (ms): 1549.5 | learning rate: 3.716E-06 | global batch size:     8 | lm loss: 5.732447E+00 | loss scale: 1.0 | grad norm: 3.336 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      283/     400 | consumed samples:         2264 | elapsed time per iteration (ms): 1453.8 | learning rate: 3.693E-06 | global batch size:     8 | lm loss: 5.722095E+00 | loss scale: 1.0 | grad norm: 3.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      284/     400 | consumed samples:         2272 | elapsed time per iteration (ms): 1469.2 | learning rate: 3.670E-06 | global batch size:     8 | lm loss: 5.651041E+00 | loss scale: 1.0 | grad norm: 5.593 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      285/     400 | consumed samples:         2280 | elapsed time per iteration (ms): 1463.6 | learning rate: 3.647E-06 | global batch size:     8 | lm loss: 5.610414E+00 | loss scale: 1.0 | grad norm: 5.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      286/     400 | consumed samples:         2288 | elapsed time per iteration (ms): 1427.3 | learning rate: 3.624E-06 | global batch size:     8 | lm loss: 5.717106E+00 | loss scale: 1.0 | grad norm: 8.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      287/     400 | consumed samples:         2296 | elapsed time per iteration (ms): 2372.4 | learning rate: 3.601E-06 | global batch size:     8 | lm loss: 5.704759E+00 | loss scale: 1.0 | grad norm: 3.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      288/     400 | consumed samples:         2304 | elapsed time per iteration (ms): 1429.8 | learning rate: 3.578E-06 | global batch size:     8 | lm loss: 5.706996E+00 | loss scale: 1.0 | grad norm: 5.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      289/     400 | consumed samples:         2312 | elapsed time per iteration (ms): 1471.9 | learning rate: 3.555E-06 | global batch size:     8 | lm loss: 5.676622E+00 | loss scale: 1.0 | grad norm: 3.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      290/     400 | consumed samples:         2320 | elapsed time per iteration (ms): 1424.1 | learning rate: 3.532E-06 | global batch size:     8 | lm loss: 5.627324E+00 | loss scale: 1.0 | grad norm: 3.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      291/     400 | consumed samples:         2328 | elapsed time per iteration (ms): 1475.3 | learning rate: 3.509E-06 | global batch size:     8 | lm loss: 5.630515E+00 | loss scale: 1.0 | grad norm: 3.373 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      292/     400 | consumed samples:         2336 | elapsed time per iteration (ms): 1497.6 | learning rate: 3.486E-06 | global batch size:     8 | lm loss: 5.717398E+00 | loss scale: 1.0 | grad norm: 3.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      293/     400 | consumed samples:         2344 | elapsed time per iteration (ms): 2300.2 | learning rate: 3.463E-06 | global batch size:     8 | lm loss: 5.610469E+00 | loss scale: 1.0 | grad norm: 3.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      294/     400 | consumed samples:         2352 | elapsed time per iteration (ms): 1466.2 | learning rate: 3.440E-06 | global batch size:     8 | lm loss: 5.573133E+00 | loss scale: 1.0 | grad norm: 7.256 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      295/     400 | consumed samples:         2360 | elapsed time per iteration (ms): 1503.7 | learning rate: 3.417E-06 | global batch size:     8 | lm loss: 5.714529E+00 | loss scale: 1.0 | grad norm: 4.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      296/     400 | consumed samples:         2368 | elapsed time per iteration (ms): 1450.5 | learning rate: 3.394E-06 | global batch size:     8 | lm loss: 5.846596E+00 | loss scale: 1.0 | grad norm: 4.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      297/     400 | consumed samples:         2376 | elapsed time per iteration (ms): 1472.0 | learning rate: 3.371E-06 | global batch size:     8 | lm loss: 6.307892E+00 | loss scale: 1.0 | grad norm: 4.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      298/     400 | consumed samples:         2384 | elapsed time per iteration (ms): 1477.1 | learning rate: 3.348E-06 | global batch size:     8 | lm loss: 5.732192E+00 | loss scale: 1.0 | grad norm: 3.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      299/     400 | consumed samples:         2392 | elapsed time per iteration (ms): 1451.5 | learning rate: 3.325E-06 | global batch size:     8 | lm loss: 6.001056E+00 | loss scale: 1.0 | grad norm: 18.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      300/     400 | consumed samples:         2400 | elapsed time per iteration (ms): 2365.4 | learning rate: 3.302E-06 | global batch size:     8 | lm loss: 5.801928E+00 | loss scale: 1.0 | grad norm: 3.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      301/     400 | consumed samples:         2408 | elapsed time per iteration (ms): 1493.0 | learning rate: 3.279E-06 | global batch size:     8 | lm loss: 5.596973E+00 | loss scale: 1.0 | grad norm: 4.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      302/     400 | consumed samples:         2416 | elapsed time per iteration (ms): 1515.7 | learning rate: 3.256E-06 | global batch size:     8 | lm loss: 5.546952E+00 | loss scale: 1.0 | grad norm: 3.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      303/     400 | consumed samples:         2424 | elapsed time per iteration (ms): 1499.8 | learning rate: 3.233E-06 | global batch size:     8 | lm loss: 5.992668E+00 | loss scale: 1.0 | grad norm: 4.214 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      304/     400 | consumed samples:         2432 | elapsed time per iteration (ms): 1474.3 | learning rate: 3.210E-06 | global batch size:     8 | lm loss: 5.523940E+00 | loss scale: 1.0 | grad norm: 3.543 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      305/     400 | consumed samples:         2440 | elapsed time per iteration (ms): 1497.5 | learning rate: 3.187E-06 | global batch size:     8 | lm loss: 6.010661E+00 | loss scale: 1.0 | grad norm: 4.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      306/     400 | consumed samples:         2448 | elapsed time per iteration (ms): 1443.7 | learning rate: 3.164E-06 | global batch size:     8 | lm loss: 5.626427E+00 | loss scale: 1.0 | grad norm: 3.176 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      307/     400 | consumed samples:         2456 | elapsed time per iteration (ms): 1458.0 | learning rate: 3.141E-06 | global batch size:     8 | lm loss: 5.728911E+00 | loss scale: 1.0 | grad norm: 2.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      308/     400 | consumed samples:         2464 | elapsed time per iteration (ms): 1506.9 | learning rate: 3.118E-06 | global batch size:     8 | lm loss: 5.668569E+00 | loss scale: 1.0 | grad norm: 3.262 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      309/     400 | consumed samples:         2472 | elapsed time per iteration (ms): 1451.3 | learning rate: 3.095E-06 | global batch size:     8 | lm loss: 5.482498E+00 | loss scale: 1.0 | grad norm: 5.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      310/     400 | consumed samples:         2480 | elapsed time per iteration (ms): 1459.2 | learning rate: 3.072E-06 | global batch size:     8 | lm loss: 5.598651E+00 | loss scale: 1.0 | grad norm: 3.308 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      311/     400 | consumed samples:         2488 | elapsed time per iteration (ms): 1482.0 | learning rate: 3.049E-06 | global batch size:     8 | lm loss: 5.879390E+00 | loss scale: 1.0 | grad norm: 3.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      312/     400 | consumed samples:         2496 | elapsed time per iteration (ms): 1520.5 | learning rate: 3.026E-06 | global batch size:     8 | lm loss: 5.770558E+00 | loss scale: 1.0 | grad norm: 4.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      313/     400 | consumed samples:         2504 | elapsed time per iteration (ms): 1441.1 | learning rate: 3.003E-06 | global batch size:     8 | lm loss: 5.720284E+00 | loss scale: 1.0 | grad norm: 2.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      314/     400 | consumed samples:         2512 | elapsed time per iteration (ms): 1485.9 | learning rate: 2.980E-06 | global batch size:     8 | lm loss: 5.637058E+00 | loss scale: 1.0 | grad norm: 3.324 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      315/     400 | consumed samples:         2520 | elapsed time per iteration (ms): 1451.9 | learning rate: 2.957E-06 | global batch size:     8 | lm loss: 5.622802E+00 | loss scale: 1.0 | grad norm: 4.365 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      316/     400 | consumed samples:         2528 | elapsed time per iteration (ms): 1498.6 | learning rate: 2.934E-06 | global batch size:     8 | lm loss: 5.713424E+00 | loss scale: 1.0 | grad norm: 3.217 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      317/     400 | consumed samples:         2536 | elapsed time per iteration (ms): 1499.4 | learning rate: 2.910E-06 | global batch size:     8 | lm loss: 5.445080E+00 | loss scale: 1.0 | grad norm: 3.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      318/     400 | consumed samples:         2544 | elapsed time per iteration (ms): 1432.8 | learning rate: 2.887E-06 | global batch size:     8 | lm loss: 5.679560E+00 | loss scale: 1.0 | grad norm: 4.248 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      319/     400 | consumed samples:         2552 | elapsed time per iteration (ms): 1437.3 | learning rate: 2.864E-06 | global batch size:     8 | lm loss: 5.678907E+00 | loss scale: 1.0 | grad norm: 7.127 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      320/     400 | consumed samples:         2560 | elapsed time per iteration (ms): 1436.7 | learning rate: 2.841E-06 | global batch size:     8 | lm loss: 5.808975E+00 | loss scale: 1.0 | grad norm: 4.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      321/     400 | consumed samples:         2568 | elapsed time per iteration (ms): 1426.1 | learning rate: 2.818E-06 | global batch size:     8 | lm loss: 5.540897E+00 | loss scale: 1.0 | grad norm: 3.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      322/     400 | consumed samples:         2576 | elapsed time per iteration (ms): 1541.4 | learning rate: 2.795E-06 | global batch size:     8 | lm loss: 5.586971E+00 | loss scale: 1.0 | grad norm: 19.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      323/     400 | consumed samples:         2584 | elapsed time per iteration (ms): 1504.0 | learning rate: 2.772E-06 | global batch size:     8 | lm loss: 5.757268E+00 | loss scale: 1.0 | grad norm: 7.132 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      324/     400 | consumed samples:         2592 | elapsed time per iteration (ms): 1494.9 | learning rate: 2.749E-06 | global batch size:     8 | lm loss: 5.622369E+00 | loss scale: 1.0 | grad norm: 3.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      325/     400 | consumed samples:         2600 | elapsed time per iteration (ms): 1506.7 | learning rate: 2.726E-06 | global batch size:     8 | lm loss: 5.424580E+00 | loss scale: 1.0 | grad norm: 3.190 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      326/     400 | consumed samples:         2608 | elapsed time per iteration (ms): 1508.7 | learning rate: 2.703E-06 | global batch size:     8 | lm loss: 6.149486E+00 | loss scale: 1.0 | grad norm: 5.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      327/     400 | consumed samples:         2616 | elapsed time per iteration (ms): 1498.8 | learning rate: 2.680E-06 | global batch size:     8 | lm loss: 5.541815E+00 | loss scale: 1.0 | grad norm: 4.208 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      328/     400 | consumed samples:         2624 | elapsed time per iteration (ms): 1485.9 | learning rate: 2.657E-06 | global batch size:     8 | lm loss: 5.397979E+00 | loss scale: 1.0 | grad norm: 3.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      329/     400 | consumed samples:         2632 | elapsed time per iteration (ms): 1503.2 | learning rate: 2.634E-06 | global batch size:     8 | lm loss: 5.740859E+00 | loss scale: 1.0 | grad norm: 4.433 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      330/     400 | consumed samples:         2640 | elapsed time per iteration (ms): 2400.9 | learning rate: 2.611E-06 | global batch size:     8 | lm loss: 5.522685E+00 | loss scale: 1.0 | grad norm: 3.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      331/     400 | consumed samples:         2648 | elapsed time per iteration (ms): 1444.1 | learning rate: 2.588E-06 | global batch size:     8 | lm loss: 5.449795E+00 | loss scale: 1.0 | grad norm: 3.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      332/     400 | consumed samples:         2656 | elapsed time per iteration (ms): 1463.1 | learning rate: 2.565E-06 | global batch size:     8 | lm loss: 5.832073E+00 | loss scale: 1.0 | grad norm: 3.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      333/     400 | consumed samples:         2664 | elapsed time per iteration (ms): 1487.1 | learning rate: 2.542E-06 | global batch size:     8 | lm loss: 5.727778E+00 | loss scale: 1.0 | grad norm: 3.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      334/     400 | consumed samples:         2672 | elapsed time per iteration (ms): 1499.9 | learning rate: 2.519E-06 | global batch size:     8 | lm loss: 5.680019E+00 | loss scale: 1.0 | grad norm: 3.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      335/     400 | consumed samples:         2680 | elapsed time per iteration (ms): 1500.4 | learning rate: 2.496E-06 | global batch size:     8 | lm loss: 5.907691E+00 | loss scale: 1.0 | grad norm: 3.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      336/     400 | consumed samples:         2688 | elapsed time per iteration (ms): 1442.1 | learning rate: 2.473E-06 | global batch size:     8 | lm loss: 5.630170E+00 | loss scale: 1.0 | grad norm: 3.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      337/     400 | consumed samples:         2696 | elapsed time per iteration (ms): 1457.3 | learning rate: 2.450E-06 | global batch size:     8 | lm loss: 5.549081E+00 | loss scale: 1.0 | grad norm: 3.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      338/     400 | consumed samples:         2704 | elapsed time per iteration (ms): 1499.6 | learning rate: 2.427E-06 | global batch size:     8 | lm loss: 5.546540E+00 | loss scale: 1.0 | grad norm: 3.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      339/     400 | consumed samples:         2712 | elapsed time per iteration (ms): 1499.9 | learning rate: 2.404E-06 | global batch size:     8 | lm loss: 5.724094E+00 | loss scale: 1.0 | grad norm: 3.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      340/     400 | consumed samples:         2720 | elapsed time per iteration (ms): 1435.7 | learning rate: 2.381E-06 | global batch size:     8 | lm loss: 5.660848E+00 | loss scale: 1.0 | grad norm: 3.197 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      341/     400 | consumed samples:         2728 | elapsed time per iteration (ms): 1463.7 | learning rate: 2.358E-06 | global batch size:     8 | lm loss: 5.635268E+00 | loss scale: 1.0 | grad norm: 3.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      342/     400 | consumed samples:         2736 | elapsed time per iteration (ms): 1500.5 | learning rate: 2.335E-06 | global batch size:     8 | lm loss: 5.637768E+00 | loss scale: 1.0 | grad norm: 3.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      343/     400 | consumed samples:         2744 | elapsed time per iteration (ms): 1529.3 | learning rate: 2.312E-06 | global batch size:     8 | lm loss: 5.764300E+00 | loss scale: 1.0 | grad norm: 6.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      344/     400 | consumed samples:         2752 | elapsed time per iteration (ms): 1427.5 | learning rate: 2.289E-06 | global batch size:     8 | lm loss: 5.800351E+00 | loss scale: 1.0 | grad norm: 3.549 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      345/     400 | consumed samples:         2760 | elapsed time per iteration (ms): 1491.3 | learning rate: 2.266E-06 | global batch size:     8 | lm loss: 5.766532E+00 | loss scale: 1.0 | grad norm: 3.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      346/     400 | consumed samples:         2768 | elapsed time per iteration (ms): 1475.6 | learning rate: 2.243E-06 | global batch size:     8 | lm loss: 5.647348E+00 | loss scale: 1.0 | grad norm: 5.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      347/     400 | consumed samples:         2776 | elapsed time per iteration (ms): 1478.6 | learning rate: 2.220E-06 | global batch size:     8 | lm loss: 5.537286E+00 | loss scale: 1.0 | grad norm: 4.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      348/     400 | consumed samples:         2784 | elapsed time per iteration (ms): 1525.6 | learning rate: 2.197E-06 | global batch size:     8 | lm loss: 5.702888E+00 | loss scale: 1.0 | grad norm: 3.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      349/     400 | consumed samples:         2792 | elapsed time per iteration (ms): 1438.1 | learning rate: 2.174E-06 | global batch size:     8 | lm loss: 5.469019E+00 | loss scale: 1.0 | grad norm: 3.346 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      350/     400 | consumed samples:         2800 | elapsed time per iteration (ms): 1532.3 | learning rate: 2.151E-06 | global batch size:     8 | lm loss: 5.766933E+00 | loss scale: 1.0 | grad norm: 3.320 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      351/     400 | consumed samples:         2808 | elapsed time per iteration (ms): 1499.8 | learning rate: 2.128E-06 | global batch size:     8 | lm loss: 5.746641E+00 | loss scale: 1.0 | grad norm: 4.532 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      352/     400 | consumed samples:         2816 | elapsed time per iteration (ms): 1514.6 | learning rate: 2.105E-06 | global batch size:     8 | lm loss: 5.625292E+00 | loss scale: 1.0 | grad norm: 3.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      353/     400 | consumed samples:         2824 | elapsed time per iteration (ms): 1518.8 | learning rate: 2.082E-06 | global batch size:     8 | lm loss: 5.610940E+00 | loss scale: 1.0 | grad norm: 3.302 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      354/     400 | consumed samples:         2832 | elapsed time per iteration (ms): 1466.8 | learning rate: 2.059E-06 | global batch size:     8 | lm loss: 5.692255E+00 | loss scale: 1.0 | grad norm: 3.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      355/     400 | consumed samples:         2840 | elapsed time per iteration (ms): 1499.0 | learning rate: 2.036E-06 | global batch size:     8 | lm loss: 5.732718E+00 | loss scale: 1.0 | grad norm: 3.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      356/     400 | consumed samples:         2848 | elapsed time per iteration (ms): 1514.8 | learning rate: 2.013E-06 | global batch size:     8 | lm loss: 5.797749E+00 | loss scale: 1.0 | grad norm: 5.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      357/     400 | consumed samples:         2856 | elapsed time per iteration (ms): 1489.5 | learning rate: 1.990E-06 | global batch size:     8 | lm loss: 5.711873E+00 | loss scale: 1.0 | grad norm: 3.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      358/     400 | consumed samples:         2864 | elapsed time per iteration (ms): 1531.7 | learning rate: 1.967E-06 | global batch size:     8 | lm loss: 5.715279E+00 | loss scale: 1.0 | grad norm: 3.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      359/     400 | consumed samples:         2872 | elapsed time per iteration (ms): 1514.1 | learning rate: 1.944E-06 | global batch size:     8 | lm loss: 5.711878E+00 | loss scale: 1.0 | grad norm: 3.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      360/     400 | consumed samples:         2880 | elapsed time per iteration (ms): 1490.6 | learning rate: 1.921E-06 | global batch size:     8 | lm loss: 5.668126E+00 | loss scale: 1.0 | grad norm: 12.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      361/     400 | consumed samples:         2888 | elapsed time per iteration (ms): 1486.6 | learning rate: 1.898E-06 | global batch size:     8 | lm loss: 5.603596E+00 | loss scale: 1.0 | grad norm: 3.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      362/     400 | consumed samples:         2896 | elapsed time per iteration (ms): 1473.4 | learning rate: 1.875E-06 | global batch size:     8 | lm loss: 5.563381E+00 | loss scale: 1.0 | grad norm: 3.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      363/     400 | consumed samples:         2904 | elapsed time per iteration (ms): 1510.3 | learning rate: 1.852E-06 | global batch size:     8 | lm loss: 5.417729E+00 | loss scale: 1.0 | grad norm: 7.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      364/     400 | consumed samples:         2912 | elapsed time per iteration (ms): 1523.0 | learning rate: 1.829E-06 | global batch size:     8 | lm loss: 5.674564E+00 | loss scale: 1.0 | grad norm: 3.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      365/     400 | consumed samples:         2920 | elapsed time per iteration (ms): 1426.8 | learning rate: 1.806E-06 | global batch size:     8 | lm loss: 5.616352E+00 | loss scale: 1.0 | grad norm: 3.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      366/     400 | consumed samples:         2928 | elapsed time per iteration (ms): 1489.8 | learning rate: 1.783E-06 | global batch size:     8 | lm loss: 5.582870E+00 | loss scale: 1.0 | grad norm: 3.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      367/     400 | consumed samples:         2936 | elapsed time per iteration (ms): 1482.7 | learning rate: 1.760E-06 | global batch size:     8 | lm loss: 5.901756E+00 | loss scale: 1.0 | grad norm: 3.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      368/     400 | consumed samples:         2944 | elapsed time per iteration (ms): 1432.1 | learning rate: 1.737E-06 | global batch size:     8 | lm loss: 5.473754E+00 | loss scale: 1.0 | grad norm: 3.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      369/     400 | consumed samples:         2952 | elapsed time per iteration (ms): 1487.2 | learning rate: 1.714E-06 | global batch size:     8 | lm loss: 5.364643E+00 | loss scale: 1.0 | grad norm: 3.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      370/     400 | consumed samples:         2960 | elapsed time per iteration (ms): 1459.7 | learning rate: 1.691E-06 | global batch size:     8 | lm loss: 5.795030E+00 | loss scale: 1.0 | grad norm: 3.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      371/     400 | consumed samples:         2968 | elapsed time per iteration (ms): 1482.2 | learning rate: 1.668E-06 | global batch size:     8 | lm loss: 5.902411E+00 | loss scale: 1.0 | grad norm: 3.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      372/     400 | consumed samples:         2976 | elapsed time per iteration (ms): 1503.6 | learning rate: 1.645E-06 | global batch size:     8 | lm loss: 5.778625E+00 | loss scale: 1.0 | grad norm: 4.567 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      373/     400 | consumed samples:         2984 | elapsed time per iteration (ms): 1500.4 | learning rate: 1.621E-06 | global batch size:     8 | lm loss: 5.618246E+00 | loss scale: 1.0 | grad norm: 3.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      374/     400 | consumed samples:         2992 | elapsed time per iteration (ms): 1550.8 | learning rate: 1.598E-06 | global batch size:     8 | lm loss: 5.810925E+00 | loss scale: 1.0 | grad norm: 3.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      375/     400 | consumed samples:         3000 | elapsed time per iteration (ms): 1486.8 | learning rate: 1.575E-06 | global batch size:     8 | lm loss: 5.450943E+00 | loss scale: 1.0 | grad norm: 3.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      376/     400 | consumed samples:         3008 | elapsed time per iteration (ms): 2459.9 | learning rate: 1.552E-06 | global batch size:     8 | lm loss: 5.846911E+00 | loss scale: 1.0 | grad norm: 8.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      377/     400 | consumed samples:         3016 | elapsed time per iteration (ms): 1502.3 | learning rate: 1.529E-06 | global batch size:     8 | lm loss: 5.727393E+00 | loss scale: 1.0 | grad norm: 3.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      378/     400 | consumed samples:         3024 | elapsed time per iteration (ms): 1463.4 | learning rate: 1.506E-06 | global batch size:     8 | lm loss: 5.642228E+00 | loss scale: 1.0 | grad norm: 3.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      379/     400 | consumed samples:         3032 | elapsed time per iteration (ms): 1501.4 | learning rate: 1.483E-06 | global batch size:     8 | lm loss: 5.618056E+00 | loss scale: 1.0 | grad norm: 3.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      380/     400 | consumed samples:         3040 | elapsed time per iteration (ms): 1502.2 | learning rate: 1.460E-06 | global batch size:     8 | lm loss: 5.648879E+00 | loss scale: 1.0 | grad norm: 3.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      381/     400 | consumed samples:         3048 | elapsed time per iteration (ms): 1499.7 | learning rate: 1.437E-06 | global batch size:     8 | lm loss: 5.638812E+00 | loss scale: 1.0 | grad norm: 3.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      382/     400 | consumed samples:         3056 | elapsed time per iteration (ms): 1439.9 | learning rate: 1.414E-06 | global batch size:     8 | lm loss: 5.953457E+00 | loss scale: 1.0 | grad norm: 3.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      383/     400 | consumed samples:         3064 | elapsed time per iteration (ms): 1488.3 | learning rate: 1.391E-06 | global batch size:     8 | lm loss: 6.723386E+00 | loss scale: 1.0 | grad norm: 5.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      384/     400 | consumed samples:         3072 | elapsed time per iteration (ms): 1469.4 | learning rate: 1.368E-06 | global batch size:     8 | lm loss: 5.773667E+00 | loss scale: 1.0 | grad norm: 4.250 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      385/     400 | consumed samples:         3080 | elapsed time per iteration (ms): 1502.5 | learning rate: 1.345E-06 | global batch size:     8 | lm loss: 5.835299E+00 | loss scale: 1.0 | grad norm: 3.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      386/     400 | consumed samples:         3088 | elapsed time per iteration (ms): 1507.2 | learning rate: 1.322E-06 | global batch size:     8 | lm loss: 5.704906E+00 | loss scale: 1.0 | grad norm: 12.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      387/     400 | consumed samples:         3096 | elapsed time per iteration (ms): 1496.6 | learning rate: 1.299E-06 | global batch size:     8 | lm loss: 5.475288E+00 | loss scale: 1.0 | grad norm: 5.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      388/     400 | consumed samples:         3104 | elapsed time per iteration (ms): 1493.3 | learning rate: 1.276E-06 | global batch size:     8 | lm loss: 5.423325E+00 | loss scale: 1.0 | grad norm: 4.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      389/     400 | consumed samples:         3112 | elapsed time per iteration (ms): 1447.5 | learning rate: 1.253E-06 | global batch size:     8 | lm loss: 5.815808E+00 | loss scale: 1.0 | grad norm: 3.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      390/     400 | consumed samples:         3120 | elapsed time per iteration (ms): 1487.2 | learning rate: 1.230E-06 | global batch size:     8 | lm loss: 5.830281E+00 | loss scale: 1.0 | grad norm: 2.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      391/     400 | consumed samples:         3128 | elapsed time per iteration (ms): 1564.9 | learning rate: 1.207E-06 | global batch size:     8 | lm loss: 6.539351E+00 | loss scale: 1.0 | grad norm: 5.157 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      392/     400 | consumed samples:         3136 | elapsed time per iteration (ms): 1502.0 | learning rate: 1.184E-06 | global batch size:     8 | lm loss: 5.678232E+00 | loss scale: 1.0 | grad norm: 3.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      393/     400 | consumed samples:         3144 | elapsed time per iteration (ms): 1497.7 | learning rate: 1.161E-06 | global batch size:     8 | lm loss: 5.547229E+00 | loss scale: 1.0 | grad norm: 11.571 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      394/     400 | consumed samples:         3152 | elapsed time per iteration (ms): 1499.6 | learning rate: 1.138E-06 | global batch size:     8 | lm loss: 5.683677E+00 | loss scale: 1.0 | grad norm: 4.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      395/     400 | consumed samples:         3160 | elapsed time per iteration (ms): 1501.6 | learning rate: 1.115E-06 | global batch size:     8 | lm loss: 5.670731E+00 | loss scale: 1.0 | grad norm: 4.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      396/     400 | consumed samples:         3168 | elapsed time per iteration (ms): 1500.5 | learning rate: 1.092E-06 | global batch size:     8 | lm loss: 5.535344E+00 | loss scale: 1.0 | grad norm: 3.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      397/     400 | consumed samples:         3176 | elapsed time per iteration (ms): 1460.6 | learning rate: 1.069E-06 | global batch size:     8 | lm loss: 5.911983E+00 | loss scale: 1.0 | grad norm: 6.542 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      398/     400 | consumed samples:         3184 | elapsed time per iteration (ms): 1451.3 | learning rate: 1.046E-06 | global batch size:     8 | lm loss: 5.689471E+00 | loss scale: 1.0 | grad norm: 3.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      399/     400 | consumed samples:         3192 | elapsed time per iteration (ms): 2399.2 | learning rate: 1.023E-06 | global batch size:     8 | lm loss: 5.566693E+00 | loss scale: 1.0 | grad norm: 3.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      400/     400 | consumed samples:         3200 | elapsed time per iteration (ms): 1448.0 | learning rate: 1.000E-06 | global batch size:     8 | lm loss: 5.930373E+00 | loss scale: 1.0 | grad norm: 4.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
Rank 6 will save checkpoint to /mnt/output_megatron_llama2/checkpoint/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000/iter_0000400/mp_rank_00_003/distrib_optim.pt
Rank 4 will save checkpoint to /mnt/output_megatron_llama2/checkpoint/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000/iter_0000400/mp_rank_00_002/distrib_optim.pt
Rank 6 will save checkpoint to /mnt/output_megatron_llama2/checkpoint/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000/iter_0000400/mp_rank_00_003/nondistrib_optim.pt
Rank 6 will save checkpoint to /mnt/output_megatron_llama2/checkpoint/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000/iter_0000400/mp_rank_00_003/model_optim_rng.pt
Rank 4 will save checkpoint to /mnt/output_megatron_llama2/checkpoint/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000/iter_0000400/mp_rank_00_002/nondistrib_optim.pt
Rank 4 will save checkpoint to /mnt/output_megatron_llama2/checkpoint/dsw-pretrain-megatron-gpt3-7B-lr-1e-5-bs-1-seqlen-128-pr-bf16-tp-1-pp-4-ac-sel-do-true-sp-false-tt-409600-wt-10000/iter_0000400/mp_rank_00_002/model_optim_rng.pt
